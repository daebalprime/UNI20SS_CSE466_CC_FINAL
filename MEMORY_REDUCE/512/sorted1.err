20/06/09 04:29:00 INFO client.RMProxy: Connecting to ResourceManager at master/10.51.17.95:8032
20/06/09 04:29:01 INFO client.RMProxy: Connecting to ResourceManager at master/10.51.17.95:8032
20/06/09 04:29:01 INFO input.FileInputFormat: Total input paths to process : 10
20/06/09 04:29:01 INFO mapreduce.JobSubmitter: number of splits:80
20/06/09 04:29:01 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1591643487177_0005
20/06/09 04:29:02 INFO impl.YarnClientImpl: Submitted application application_1591643487177_0005
20/06/09 04:29:02 INFO mapreduce.Job: The url to track the job: http://master:8088/proxy/application_1591643487177_0005/
20/06/09 04:29:02 INFO mapreduce.Job: Running job: job_1591643487177_0005
20/06/09 04:29:10 INFO mapreduce.Job: Job job_1591643487177_0005 running in uber mode : false
20/06/09 04:29:10 INFO mapreduce.Job:  map 0% reduce 0%
20/06/09 04:29:20 INFO mapreduce.Job:  map 3% reduce 0%
20/06/09 04:29:21 INFO mapreduce.Job:  map 4% reduce 0%
20/06/09 04:29:22 INFO mapreduce.Job:  map 6% reduce 0%
20/06/09 04:29:23 INFO mapreduce.Job:  map 8% reduce 0%
20/06/09 04:29:28 INFO mapreduce.Job:  map 9% reduce 0%
20/06/09 04:29:29 INFO mapreduce.Job:  map 10% reduce 0%
20/06/09 04:29:31 INFO mapreduce.Job:  map 11% reduce 0%
20/06/09 04:29:32 INFO mapreduce.Job:  map 14% reduce 0%
20/06/09 04:29:33 INFO mapreduce.Job:  map 15% reduce 0%
20/06/09 04:29:38 INFO mapreduce.Job:  map 16% reduce 0%
20/06/09 04:29:39 INFO mapreduce.Job:  map 17% reduce 0%
20/06/09 04:29:41 INFO mapreduce.Job:  map 19% reduce 0%
20/06/09 04:29:45 INFO mapreduce.Job:  map 21% reduce 2%
20/06/09 04:29:46 INFO mapreduce.Job:  map 22% reduce 4%
20/06/09 04:29:48 INFO mapreduce.Job:  map 24% reduce 5%
20/06/09 04:29:50 INFO mapreduce.Job:  map 26% reduce 5%
20/06/09 04:29:51 INFO mapreduce.Job:  map 28% reduce 5%
20/06/09 04:29:52 INFO mapreduce.Job:  map 28% reduce 6%
20/06/09 04:29:53 INFO mapreduce.Job:  map 29% reduce 6%
20/06/09 04:29:56 INFO mapreduce.Job:  map 32% reduce 7%
20/06/09 04:29:58 INFO mapreduce.Job:  map 34% reduce 8%
20/06/09 04:29:59 INFO mapreduce.Job:  map 35% reduce 8%
20/06/09 04:30:00 INFO mapreduce.Job:  map 35% reduce 9%
20/06/09 04:30:04 INFO mapreduce.Job:  map 39% reduce 9%
20/06/09 04:30:05 INFO mapreduce.Job:  map 39% reduce 10%
20/06/09 04:30:07 INFO mapreduce.Job:  map 41% reduce 11%
20/06/09 04:30:08 INFO mapreduce.Job:  map 43% reduce 11%
20/06/09 04:30:09 INFO mapreduce.Job:  map 44% reduce 11%
20/06/09 04:30:11 INFO mapreduce.Job:  map 46% reduce 11%
20/06/09 04:30:12 INFO mapreduce.Job:  map 46% reduce 12%
20/06/09 04:30:13 INFO mapreduce.Job:  map 47% reduce 12%
20/06/09 04:30:15 INFO mapreduce.Job:  map 50% reduce 12%
20/06/09 04:30:16 INFO mapreduce.Job:  map 50% reduce 13%
20/06/09 04:30:17 INFO mapreduce.Job:  map 51% reduce 13%
20/06/09 04:30:19 INFO mapreduce.Job:  map 54% reduce 13%
20/06/09 04:30:20 INFO mapreduce.Job:  map 55% reduce 14%
20/06/09 04:30:21 INFO mapreduce.Job:  map 56% reduce 14%
20/06/09 04:30:22 INFO mapreduce.Job:  map 57% reduce 14%
20/06/09 04:30:23 INFO mapreduce.Job:  map 58% reduce 14%
20/06/09 04:30:25 INFO mapreduce.Job:  map 60% reduce 15%
20/06/09 04:30:27 INFO mapreduce.Job:  map 61% reduce 15%
20/06/09 04:30:28 INFO mapreduce.Job:  map 62% reduce 15%
20/06/09 04:30:29 INFO mapreduce.Job:  map 62% reduce 16%
20/06/09 04:30:30 INFO mapreduce.Job:  map 63% reduce 16%
20/06/09 04:30:32 INFO mapreduce.Job:  map 64% reduce 16%
20/06/09 04:30:33 INFO mapreduce.Job:  map 65% reduce 16%
20/06/09 04:30:35 INFO mapreduce.Job:  map 65% reduce 17%
20/06/09 04:30:37 INFO mapreduce.Job:  map 66% reduce 17%
20/06/09 04:30:38 INFO mapreduce.Job:  map 67% reduce 17%
20/06/09 04:30:43 INFO mapreduce.Job:  map 69% reduce 17%
20/06/09 04:30:44 INFO mapreduce.Job:  map 70% reduce 17%
20/06/09 04:30:45 INFO mapreduce.Job:  map 72% reduce 17%
20/06/09 04:30:45 INFO mapreduce.Job: Task Id : attempt_1591643487177_0005_m_000055_0, Status : FAILED
Error: org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find any valid local directory for output/attempt_1591643487177_0005_m_000055_0/file.out
	at org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.getLocalPathForWrite(LocalDirAllocator.java:402)
	at org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:150)
	at org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:131)
	at org.apache.hadoop.mapred.YarnOutputFiles.getOutputFileForWrite(YarnOutputFiles.java:84)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.mergeParts(MapTask.java:1841)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1511)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1758)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)

Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

20/06/09 04:30:48 INFO mapreduce.Job: Task Id : attempt_1591643487177_0005_m_000054_0, Status : FAILED
Error: org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find any valid local directory for attempt_1591643487177_0005_m_000054_0_spill_1.out
	at org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.getLocalPathForWrite(LocalDirAllocator.java:402)
	at org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:150)
	at org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:131)
	at org.apache.hadoop.mapred.YarnOutputFiles.getSpillFileForWrite(YarnOutputFiles.java:159)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1592)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1758)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)

Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

20/06/09 04:30:48 INFO mapreduce.Job: Task Id : attempt_1591643487177_0005_m_000060_0, Status : FAILED
Error: java.io.IOException: Spill failed
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.checkSpillException(MapTask.java:1562)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:1085)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:715)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at org.apache.hadoop.mapreduce.Mapper.map(Mapper.java:125)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1758)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find any valid local directory for attempt_1591643487177_0005_m_000060_0_spill_0.out
	at org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.getLocalPathForWrite(LocalDirAllocator.java:402)
	at org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:150)
	at org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:131)
	at org.apache.hadoop.mapred.YarnOutputFiles.getSpillFileForWrite(YarnOutputFiles.java:159)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1592)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.access$900(MapTask.java:876)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer$SpillThread.run(MapTask.java:1532)

Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

20/06/09 04:30:48 INFO mapreduce.Job: Task Id : attempt_1591643487177_0005_m_000056_0, Status : FAILED
Error: org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find any valid local directory for attempt_1591643487177_0005_m_000056_0_spill_1.out
	at org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.getLocalPathForWrite(LocalDirAllocator.java:402)
	at org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:150)
	at org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:131)
	at org.apache.hadoop.mapred.YarnOutputFiles.getSpillFileForWrite(YarnOutputFiles.java:159)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1592)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1758)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)

20/06/09 04:30:49 INFO mapreduce.Job:  map 68% reduce 17%
20/06/09 04:30:49 INFO mapreduce.Job: Task Id : attempt_1591643487177_0005_m_000057_0, Status : FAILED
Error: org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find any valid local directory for attempt_1591643487177_0005_m_000057_0_spill_1.out
	at org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.getLocalPathForWrite(LocalDirAllocator.java:402)
	at org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:150)
	at org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:131)
	at org.apache.hadoop.mapred.YarnOutputFiles.getSpillFileForWrite(YarnOutputFiles.java:159)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1592)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1758)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)

20/06/09 04:30:49 INFO mapreduce.Job: Task Id : attempt_1591643487177_0005_m_000058_0, Status : FAILED
Error: org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find any valid local directory for attempt_1591643487177_0005_m_000058_0_spill_1.out
	at org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.getLocalPathForWrite(LocalDirAllocator.java:402)
	at org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:150)
	at org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:131)
	at org.apache.hadoop.mapred.YarnOutputFiles.getSpillFileForWrite(YarnOutputFiles.java:159)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1592)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1489)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1758)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)

20/06/09 04:30:49 INFO mapreduce.Job: Task Id : attempt_1591643487177_0005_r_000001_0, Status : FAILED
Error: org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in fetcher#5
	at org.apache.hadoop.mapreduce.task.reduce.Shuffle.run(Shuffle.java:134)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:376)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1758)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: org.apache.hadoop.fs.FSError: java.io.IOException: No space left on device
	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.write(RawLocalFileSystem.java:248)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:58)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.mapreduce.task.reduce.OnDiskMapOutput.shuffle(OnDiskMapOutput.java:108)
	at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyMapOutput(Fetcher.java:534)
	at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyFromHost(Fetcher.java:333)
	at org.apache.hadoop.mapreduce.task.reduce.Fetcher.run(Fetcher.java:193)
Caused by: java.io.IOException: No space left on device
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:326)
	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.write(RawLocalFileSystem.java:246)
	... 7 more

20/06/09 04:30:50 INFO mapreduce.Job:  map 69% reduce 12%
20/06/09 04:30:51 INFO mapreduce.Job:  map 70% reduce 12%
20/06/09 04:30:51 INFO mapreduce.Job: Task Id : attempt_1591643487177_0005_r_000002_0, Status : FAILED
Error: org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in fetcher#4
	at org.apache.hadoop.mapreduce.task.reduce.Shuffle.run(Shuffle.java:134)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:376)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1758)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: org.apache.hadoop.fs.FSError: java.io.IOException: No space left on device
	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.write(RawLocalFileSystem.java:248)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:58)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.mapreduce.task.reduce.OnDiskMapOutput.shuffle(OnDiskMapOutput.java:108)
	at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyMapOutput(Fetcher.java:534)
	at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyFromHost(Fetcher.java:333)
	at org.apache.hadoop.mapreduce.task.reduce.Fetcher.run(Fetcher.java:193)
Caused by: java.io.IOException: No space left on device
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:326)
	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.write(RawLocalFileSystem.java:246)
	... 7 more

20/06/09 04:30:52 INFO mapreduce.Job:  map 71% reduce 8%
20/06/09 04:30:53 INFO mapreduce.Job:  map 72% reduce 8%
20/06/09 04:30:53 INFO mapreduce.Job: Task Id : attempt_1591643487177_0005_m_000055_1, Status : FAILED
mkdir of /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1591643487177_0005/container_1591643487177_0005_01_000070 failed

20/06/09 04:30:54 INFO mapreduce.Job:  map 73% reduce 8%
20/06/09 04:30:55 INFO mapreduce.Job:  map 74% reduce 8%
20/06/09 04:30:57 INFO mapreduce.Job: Task Id : attempt_1591643487177_0005_m_000064_0, Status : FAILED
/tmp/hadoop-root/nm-local-dir/nmPrivate/application_1591643487177_0005/container_1591643487177_0005_01_000069/.launch_container.sh.crc (No space left on device)

20/06/09 04:30:58 INFO mapreduce.Job: Task Id : attempt_1591643487177_0005_m_000057_1, Status : FAILED
mkdir of /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1591643487177_0005/container_1591643487177_0005_01_000074 failed

20/06/09 04:30:58 INFO mapreduce.Job: Task Id : attempt_1591643487177_0005_m_000060_1, Status : FAILED
Exception from container-launch.
Container id: container_1591643487177_0005_01_000072
Exit code: 1
Exception message: /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1591643487177_0005/container_1591643487177_0005_01_000072/default_container_executor_session.sh: line 3: /tmp/hadoop-root/nm-local-dir/nmPrivate/application_1591643487177_0005/container_1591643487177_0005_01_000072/container_1591643487177_0005_01_000072.pid.tmp: No space left on device
/bin/mv: cannot stat ‘/tmp/hadoop-root/nm-local-dir/nmPrivate/application_1591643487177_0005/container_1591643487177_0005_01_000072/container_1591643487177_0005_01_000072.pid.tmp’: No such file or directory
ln: failed to create symbolic link ‘job.xml’: No space left on device
/tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1591643487177_0005/container_1591643487177_0005_01_000072/default_container_executor.sh: line 4: /tmp/hadoop-root/nm-local-dir/nmPrivate/application_1591643487177_0005/container_1591643487177_0005_01_000072/container_1591643487177_0005_01_000072.pid.exitcode.tmp: No space left on device
/bin/mv: cannot stat ‘/tmp/hadoop-root/nm-local-dir/nmPrivate/application_1591643487177_0005/container_1591643487177_0005_01_000072/container_1591643487177_0005_01_000072.pid.exitcode.tmp’: No such file or directory

Stack trace: ExitCodeException exitCode=1: /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1591643487177_0005/container_1591643487177_0005_01_000072/default_container_executor_session.sh: line 3: /tmp/hadoop-root/nm-local-dir/nmPrivate/application_1591643487177_0005/container_1591643487177_0005_01_000072/container_1591643487177_0005_01_000072.pid.tmp: No space left on device
/bin/mv: cannot stat ‘/tmp/hadoop-root/nm-local-dir/nmPrivate/application_1591643487177_0005/container_1591643487177_0005_01_000072/container_1591643487177_0005_01_000072.pid.tmp’: No such file or directory
ln: failed to create symbolic link ‘job.xml’: No space left on device
/tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1591643487177_0005/container_1591643487177_0005_01_000072/default_container_executor.sh: line 4: /tmp/hadoop-root/nm-local-dir/nmPrivate/application_1591643487177_0005/container_1591643487177_0005_01_000072/container_1591643487177_0005_01_000072.pid.exitcode.tmp: No space left on device
/bin/mv: cannot stat ‘/tmp/hadoop-root/nm-local-dir/nmPrivate/application_1591643487177_0005/container_1591643487177_0005_01_000072/container_1591643487177_0005_01_000072.pid.exitcode.tmp’: No such file or directory

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:585)
	at org.apache.hadoop.util.Shell.run(Shell.java:482)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:776)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1

20/06/09 04:30:58 INFO mapreduce.Job: Task Id : attempt_1591643487177_0005_m_000058_1, Status : FAILED
Could not find any valid local directory for nmPrivate/application_1591643487177_0005/container_1591643487177_0005_01_000075//launch_container.sh

20/06/09 04:30:58 INFO mapreduce.Job: Task Id : attempt_1591643487177_0005_m_000056_1, Status : FAILED
/tmp/hadoop-root/nm-local-dir/nmPrivate/application_1591643487177_0005/container_1591643487177_0005_01_000073/launch_container.sh (No space left on device)

20/06/09 04:30:59 INFO mapreduce.Job:  map 75% reduce 8%
20/06/09 04:30:59 INFO mapreduce.Job: Task Id : attempt_1591643487177_0005_m_000066_0, Status : FAILED
mkdir of /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1591643487177_0005/container_1591643487177_0005_01_000076 failed

20/06/09 04:30:59 INFO mapreduce.Job: Task Id : attempt_1591643487177_0005_r_000002_1, Status : FAILED
Exception from container-launch.
Container id: container_1591643487177_0005_01_000079
Exit code: 1
Exception message: ln: failed to create symbolic link ‘job.xml’: No space left on device

Stack trace: ExitCodeException exitCode=1: ln: failed to create symbolic link ‘job.xml’: No space left on device

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:585)
	at org.apache.hadoop.util.Shell.run(Shell.java:482)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:776)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1

20/06/09 04:31:03 INFO mapreduce.Job: Task Id : attempt_1591643487177_0005_m_000070_0, Status : FAILED
Exception from container-launch.
Container id: container_1591643487177_0005_01_000085
Exit code: 1
Exception message: ln: failed to create symbolic link ‘job.xml’: No space left on device

Stack trace: ExitCodeException exitCode=1: ln: failed to create symbolic link ‘job.xml’: No space left on device

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:585)
	at org.apache.hadoop.util.Shell.run(Shell.java:482)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:776)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1

20/06/09 04:31:03 INFO mapreduce.Job: Task Id : attempt_1591643487177_0005_m_000069_0, Status : FAILED
mkdir of /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1591643487177_0005/container_1591643487177_0005_01_000084 failed

20/06/09 04:31:03 INFO mapreduce.Job: Task Id : attempt_1591643487177_0005_m_000058_2, Status : FAILED
/tmp/hadoop-root/nm-local-dir/nmPrivate/application_1591643487177_0005/container_1591643487177_0005_01_000088/launch_container.sh (No space left on device)

20/06/09 04:31:04 INFO mapreduce.Job:  map 77% reduce 11%
20/06/09 04:31:06 INFO mapreduce.Job:  map 79% reduce 11%
20/06/09 04:31:06 INFO mapreduce.Job: Task Id : attempt_1591643487177_0005_m_000057_2, Status : FAILED
Not able to initialize container-log directories in any of the configured local directories for container container_1591643487177_0005_01_000086

20/06/09 04:31:07 INFO mapreduce.Job:  map 79% reduce 12%
20/06/09 04:31:08 INFO mapreduce.Job:  map 80% reduce 12%
20/06/09 04:31:08 INFO mapreduce.Job: Task Id : attempt_1591643487177_0005_m_000066_1, Status : FAILED
Could not find any valid local directory for nmPrivate/application_1591643487177_0005/container_1591643487177_0005_01_000090//launch_container.sh

20/06/09 04:31:08 INFO mapreduce.Job: Task Id : attempt_1591643487177_0005_m_000060_2, Status : FAILED
Exception from container-launch.
Container id: container_1591643487177_0005_01_000087
Exit code: 1
Exception message: /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1591643487177_0005/container_1591643487177_0005_01_000087/default_container_executor_session.sh: line 3: /tmp/hadoop-root/nm-local-dir/nmPrivate/application_1591643487177_0005/container_1591643487177_0005_01_000087/container_1591643487177_0005_01_000087.pid.tmp: No space left on device
/bin/mv: cannot stat ‘/tmp/hadoop-root/nm-local-dir/nmPrivate/application_1591643487177_0005/container_1591643487177_0005_01_000087/container_1591643487177_0005_01_000087.pid.tmp’: No such file or directory
ln: failed to create symbolic link ‘job.xml’: No space left on device
/tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1591643487177_0005/container_1591643487177_0005_01_000087/default_container_executor.sh: line 4: /tmp/hadoop-root/nm-local-dir/nmPrivate/application_1591643487177_0005/container_1591643487177_0005_01_000087/container_1591643487177_0005_01_000087.pid.exitcode.tmp: No space left on device
/bin/mv: cannot stat ‘/tmp/hadoop-root/nm-local-dir/nmPrivate/application_1591643487177_0005/container_1591643487177_0005_01_000087/container_1591643487177_0005_01_000087.pid.exitcode.tmp’: No such file or directory

Stack trace: ExitCodeException exitCode=1: /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1591643487177_0005/container_1591643487177_0005_01_000087/default_container_executor_session.sh: line 3: /tmp/hadoop-root/nm-local-dir/nmPrivate/application_1591643487177_0005/container_1591643487177_0005_01_000087/container_1591643487177_0005_01_000087.pid.tmp: No space left on device
/bin/mv: cannot stat ‘/tmp/hadoop-root/nm-local-dir/nmPrivate/application_1591643487177_0005/container_1591643487177_0005_01_000087/container_1591643487177_0005_01_000087.pid.tmp’: No such file or directory
ln: failed to create symbolic link ‘job.xml’: No space left on device
/tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1591643487177_0005/container_1591643487177_0005_01_000087/default_container_executor.sh: line 4: /tmp/hadoop-root/nm-local-dir/nmPrivate/application_1591643487177_0005/container_1591643487177_0005_01_000087/container_1591643487177_0005_01_000087.pid.exitcode.tmp: No space left on device
/bin/mv: cannot stat ‘/tmp/hadoop-root/nm-local-dir/nmPrivate/application_1591643487177_0005/container_1591643487177_0005_01_000087/container_1591643487177_0005_01_000087.pid.exitcode.tmp’: No such file or directory

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:585)
	at org.apache.hadoop.util.Shell.run(Shell.java:482)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:776)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1

20/06/09 04:31:08 INFO mapreduce.Job: Task Id : attempt_1591643487177_0005_m_000069_1, Status : FAILED
/tmp/hadoop-root/nm-local-dir/nmPrivate/application_1591643487177_0005/container_1591643487177_0005_01_000093/launch_container.sh (No space left on device)

20/06/09 04:31:08 INFO mapreduce.Job: Task Id : attempt_1591643487177_0005_m_000073_0, Status : FAILED
/tmp/hadoop-root/nm-local-dir/nmPrivate/application_1591643487177_0005/container_1591643487177_0005_01_000096/container_1591643487177_0005_01_000096.tokens (No space left on device)

20/06/09 04:31:08 INFO mapreduce.Job: Task Id : attempt_1591643487177_0005_m_000070_1, Status : FAILED
/tmp/hadoop-root/nm-local-dir/nmPrivate/application_1591643487177_0005/container_1591643487177_0005_01_000092/container_1591643487177_0005_01_000092.tokens (No space left on device)

20/06/09 04:31:08 INFO mapreduce.Job: Task Id : attempt_1591643487177_0005_m_000056_2, Status : FAILED
/tmp/hadoop-root/nm-local-dir/nmPrivate/application_1591643487177_0005/container_1591643487177_0005_01_000089/container_1591643487177_0005_01_000089.tokens (No space left on device)

20/06/09 04:31:08 INFO mapreduce.Job: Task Id : attempt_1591643487177_0005_m_000071_0, Status : FAILED
Could not find any valid local directory for nmPrivate/application_1591643487177_0005/container_1591643487177_0005_01_000091//launch_container.sh

20/06/09 04:31:09 INFO mapreduce.Job: Task Id : attempt_1591643487177_0005_m_000074_0, Status : FAILED
/tmp/hadoop-root/nm-local-dir/nmPrivate/application_1591643487177_0005/container_1591643487177_0005_01_000099/container_1591643487177_0005_01_000099.tokens (No space left on device)

20/06/09 04:31:10 INFO mapreduce.Job:  map 80% reduce 13%
20/06/09 04:31:11 INFO mapreduce.Job: Task Id : attempt_1591643487177_0005_m_000066_2, Status : FAILED
/tmp/hadoop-root/nm-local-dir/nmPrivate/application_1591643487177_0005/container_1591643487177_0005_01_000101/container_1591643487177_0005_01_000101.tokens (No space left on device)

20/06/09 04:31:12 INFO mapreduce.Job:  map 100% reduce 100%
20/06/09 04:31:13 INFO mapreduce.Job: Job job_1591643487177_0005 failed with state FAILED due to: Task failed task_1591643487177_0005_m_000057
Job failed as tasks failed. failedMaps:1 failedReduces:0

20/06/09 04:31:13 INFO mapreduce.Job: Counters: 42
	File System Counters
		FILE: Number of bytes read=8609026828
		FILE: Number of bytes written=17224270680
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=8626267739
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=256
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Job Counters 
		Failed map tasks=28
		Failed reduce tasks=3
		Killed map tasks=14
		Killed reduce tasks=3
		Launched map tasks=97
		Launched reduce tasks=6
		Other local map tasks=21
		Data-local map tasks=46
		Rack-local map tasks=30
		Total time spent by all maps in occupied slots (ms)=894239
		Total time spent by all reduces in occupied slots (ms)=266417
		Total time spent by all map tasks (ms)=894239
		Total time spent by all reduce tasks (ms)=266417
		Total vcore-milliseconds taken by all map tasks=894239
		Total vcore-milliseconds taken by all reduce tasks=266417
		Total megabyte-milliseconds taken by all map tasks=915700736
		Total megabyte-milliseconds taken by all reduce tasks=272811008
	Map-Reduce Framework
		Map input records=818414
		Map output records=818414
		Map output bytes=8603594112
		Map output materialized bytes=8608196177
		Input split bytes=7232
		Combine input records=0
		Spilled Records=1636828
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=10127
		CPU time spent (ms)=116770
		Physical memory (bytes) snapshot=17214529536
		Virtual memory (bytes) snapshot=135014293504
		Total committed heap usage (bytes)=13077839872
	File Input Format Counters 
		Bytes Read=8626260507
